dat2 = matrix(rnorm(unif4[2]*2, mean=+4, sd=0.5),ncol=2)
dat3 = cbind(rnorm(unif4[3], mean=+4, sd=0.5), rnorm(unif4[3], mean=-4, sd=0.5))
dat4 = cbind(rnorm(unif4[4], mean=-4, sd=0.5), rnorm(unif4[4], mean=+4, sd=0.5))
myatoms = list()
myatoms[[1]] = dat1
myatoms[[2]] = dat2
myatoms[[3]] = dat3
myatoms[[4]] = dat4
## COMPUTE
fsbary = rbary23L(myatoms)
## VISUALIZE
#  aligned with CRAN convention
opar <- par(no.readonly=TRUE)
#  plot the input measures
plot(myatoms[[1]], col="gray90", pch=19, cex=0.5, xlim=c(-6,6), ylim=c(-6,6), main="Input Measures")
points(myatoms[[2]], col="gray90", pch=19, cex=0.5)
points(myatoms[[3]], col="gray90", pch=19, cex=0.5)
points(myatoms[[4]], col="gray90", pch=19, cex=0.5)
#  plot the barycenter
points(fsbary$support, col="red", cex=1.5)
par(opar)
pkgdown::build_site()
graphics.off()
rm(list=ls())
#
# * class 1 : samples from Gaussian with mean=(-4, -4)
# * class 2 : samples from Gaussian with mean=(+4, +4)
# * target support consists of 7 integer points from -6 to 6,
#   where ideally, weight is concentrated near 0 since it's average!
#-------------------------------------------------------------------
## GENERATE DATA
#  Empirical Measures
set.seed(100)
ndat = 100
dat1 = matrix(rnorm(ndat*2, mean=-4, sd=0.5),ncol=2)
dat2 = matrix(rnorm(ndat*2, mean=+4, sd=0.5),ncol=2)
myatoms = list()
myatoms[[1]] = dat1
myatoms[[2]] = dat2
mydata = rbind(dat1, dat2)
#  Fixed Support
support = cbind(seq(from=-8,to=8,by=2),
seq(from=-8,to=8,by=2))
## COMPUTE
comp1 = fbary14C(support, myatoms, lambda=0.5, maxiter=10)
comp2 = fbary14C(support, myatoms, lambda=1,   maxiter=10)
comp3 = fbary14C(support, myatoms, lambda=10,  maxiter=10)
## VISUALIZE
opar <- par(no.readonly=TRUE)
par(mfrow=c(1,3), pty="s")
barplot(comp1, ylim=c(0,1), main="Probability\n (lambda=0.5)")
barplot(comp2, ylim=c(0,1), main="Probability\n (lambda=1)")
barplot(comp3, ylim=c(0,1), main="Probability\n (lambda=10)")
par(opar)
#
# * class 1 : samples from Gaussian with mean=(-4, -4)
# * class 2 : samples from Gaussian with mean=(+4, +4)
# * target support consists of 7 integer points from -6 to 6,
#   where ideally, weight is concentrated near 0 since it's average!
#-------------------------------------------------------------------
## GENERATE DATA
#  Empirical Measures
set.seed(100)
ndat = 100
dat1 = matrix(rnorm(ndat*2, mean=-4, sd=0.5),ncol=2)
dat2 = matrix(rnorm(ndat*2, mean=+4, sd=0.5),ncol=2)
myatoms = list()
myatoms[[1]] = dat1
myatoms[[2]] = dat2
mydata = rbind(dat1, dat2)
#  Fixed Support
support = cbind(seq(from=-8,to=8,by=2),
seq(from=-8,to=8,by=2))
## COMPUTE
comp1 = fbary14C(support, myatoms, lambda=0.5, maxiter=10)
comp2 = fbary14C(support, myatoms, lambda=1,   maxiter=10)
comp3 = fbary14C(support, myatoms, lambda=10,  maxiter=10)
## VISUALIZE
opar <- par(no.readonly=TRUE)
par(mfrow=c(1,3), pty="s")
barplot(comp1, ylim=c(0,1), main="Probability\n (lambda=0.5)")
barplot(comp2, ylim=c(0,1), main="Probability\n (lambda=1)")
barplot(comp3, ylim=c(0,1), main="Probability\n (lambda=10)")
par(opar)
pkgdown::build_site()
library(T4transport)
install.packages("RcppBH")
install.packages(c("doFuture", "future", "future.apply", "globals", "mgcv"))
pkgdown::build_site()
pkgdown::build_site()
pkgdown::clean_site()
pkgdown::build_site()
pkgdown::build_site()
pkgdown::clean_site()
pkgdown::build_site()
pkgdown::build_site()
pkgdown::build_site()
pkgdown::clean_site()
pkgdown::build_site()
pkgdown::build_site()
pkgdown::build_site()
pkgdown::build_home()
pkgdown::build_home()
pkgdown::build_home()
pkgdown::preview_site()
pkgdown::build_articles()
pkgdown::build_home()
pkgdown::preview_site()
pkgdown::build_site()
pkgdown::clean_site()
pkgdown::build_site()
pkgdown::clean_site()
pkgdown::build_site()
pkgdown::build_articles()
pkgdown::clean_site()
pkgdown::build_site()
pkgdown::build_articles()
pkgdown::clean_site()
pkgdown::build_site()
pkgdown::build_articles()
pkgdown::preview_site(path='articles/basic_compute_distance.html')
pkgdown::build_articles()
pkgdown::preview_site(path='articles/basic_compute_distance.html')
pkgdown::build_articles()
pkgdown::preview_site(path='articles/basic_compute_distance.html')
pkgdown::build_articles()
pkgdown::preview_site(path='articles/basic_compute_distance.html')
pkgdown::build_articles()
pkgdown::build_articles()
pkgdown::preview_site(path='articles/basic_compute_distance.html')
pkgdown::build_articles()
pkgdown::preview_site(path='articles/basic_compute_distance.html')
pkgdown::build_articles()
pkgdown::preview_site(path='articles/basic_compute_distance.html')
pkgdown::build_articles()
pkgdown::preview_site(path='articles/basic_compute_distance.html')
pkgdown::build_articles()
pkgdown::preview_site(path='articles/basic_compute_distance.html')
pkgdown::build_articles()
pkgdown::preview_site(path='articles/basic_compute_distance.html')
pkgdown::build_articles()
pkgdown::preview_site(path='articles/basic_compute_distance.html')
pkgdown::build_articles()
pkgdown::preview_site(path='articles/basic_compute_distance.html')
install.packages("mlbench", dependencies = TRUE)
pkgdown::build_articles(); pkgdown::preview_site(path='articles/basic_compute_distance.html')
knitr::opts_chunk$set(cache = TRUE)
library(mlbench)
# generate two datasets
data_spiral = mlbench.1spiral(n=100, cycle=1, sd=0.5)
data_spiral
plot(data_spiral)
# generate two datasets
data_spiral = mlbench.spirals(n=100, cycle=2, sd=0.5)
plot(data_spiral)
# generate two datasets
data1 = mlbench.cassini(n=100)
plot(data1)
# generate two datasets
data1 = mlbench.cassini(n=100)
data2 = mlbench.smiley(n=100)
# translate
data2[,1] = data2[,1] + 5
data2
# generate two datasets
data1 = mlbench.cassini(n=100)
data1
# generate two datasets
data1 = mlbench.cassini(n=100)$x
data2 = mlbench.smiley(n=100)$x
# translate
data2[,1] = data2[,1] + 5
# plot the datasets
plot(data1, col="blue", pch=19, cex=0.5, main="Two datasets")
points(data2)
data2
head(data2)
# plot the datasets
plot(data1, col="blue", pch=19, cex=0.5, main="Two datasets")
points(data2)
help(points)
# plot the datasets
plot(data1, col="blue", pch=19, cex=0.5, main="Two datasets")
points(data2[,1], data[,2], col="red", cex=0.5, pch=19)
library(mlbench)
# generate two datasets
data1 = mlbench.cassini(n=100)$x
data2 = mlbench.smiley(n=100)$x
# translate
data2[,1] = data2[,1] + 5
# plot the datasets
plot(data1, col="blue", pch=19, cex=0.5, main="Two datasets")
points(data2[,1], data[,2], col="red", cex=0.5, pch=19)
max(data2[,1])
# plot the datasets
plot(data1, col="blue", pch=19, cex=0.5, main="Two datasets", xlim=c(-1.5, 6))
points(data2[,1], data2[,2], col="red", cex=0.5, pch=19)
help("mlbench.smiley")
pkgdown::build_articles(); pkgdown::preview_site(path='articles/basic_compute_distance.html')
pkgdown::build_articles(); pkgdown::preview_site(path='articles/basic_compute_distance.html')
pkgdown::build_articles(); pkgdown::preview_site
pkgdown::build_articles(); pkgdown::preview_site
pkgdown::build_articles(); pkgdown::preview_site()
pkgdown::build_articles(); pkgdown::preview_site()
pkgdown::build_articles(); pkgdown::preview_site()
pkgdown::build_articles(); pkgdown::preview_site
pkgdown::build_articles(); pkgdown::preview_site()
help("wasserstein")
# call the function
output = wasserstein(data1, data2, p=2)
output
pkgdown::build_articles(); pkgdown::preview_site()
pkgdown::preview_site()
pkgdown::build_articles(); pkgdown::preview_site()
pkgdown::clean_cache()
pkgdown::build_articles()
pkgdown::preview_site()
pkgdown::build_articles(preview=TRUE)
P = output$plan
maxP = max(P)
maxP
pkgdown::build_articles(preview=TRUE)
pkgdown::build_articles(preview=TRUE)
pkgdown::build_articles(preview=TRUE)
pkgdown::build_articles(preview=TRUE)
pkgdown::build_articles(preview=TRUE)
pkgdown::build_articles(preview=TRUE)
pkgdown::build_articles(preview=TRUE)
pkgdown::build_articles(preview=TRUE)
pkgdown::build_articles(preview=TRUE)
pkgdown::build_articles(preview=TRUE)
install.packages("proxy")
pkgdown::build_articles(preview=TRUE)
pkgdown::clean_site()
pkgdown::build_site()
pkgdown::build_articles()
pkgdown::build_articles(preview=TRUE)
pkgdown::clean_cache()
pkgdown::build_site()
.Last.error
pkgdown::clean_cache()
pkgdown::build_site()
pkgdown::clean_site()
pkgdown::build_site()
pkgdown::clean_site()
pkgdown::build_site()
pkgdown::build_articles()
pkgdown::clean_site()
pkgdown::clean_cache()
pkgdown::build_site()
pkgdown::build_site()
pkgdown::clean_cache()
pkgdown::clean_site()
pkgdown::build_site()
pkgdown::clean_site()
pkgdown::clean_cache()
pkgdown::build_site()
pkgdown::clean_cache()
pkgdown::clean_site()
pkgdown::build_site()
pkgdown::build_site()
pkgdown::build_site()
install.packages("openalexR", dependencies = TRUE)
file.edit("~/.Renviron")
# personal example
# generate "n_good" measures from N(0, I)
#           "n_bad" measures from N(20, I)
n_pts = 30
n_goods = 17
n_bad = 3
input_measures = list()
for (i in 1:n_goods){
input_measures[[i]] = matrix(rnorm(n_pts*2), ncol=2)
}
for (i in (n_goods+1):(n_goods+n_bad)){
translated = matrix(rnorm(n_pts*2), ncol=2)
translated[,1] = translated[,1] + 20
input_measures[[i]] = translated
}
run_bary = rbaryGD(input_measures, num_support = n_pts)
run_median = rmedIRLS(input_measures, num_support = n_pts)
help(rmedIRLS)
help(rbaryGD)
help(rmedIRLS)
# personal example
# generate "n_good" measures from N(0, I)
#           "n_bad" measures from N(20, I)
n_pts = 30
n_goods = 17
n_bad = 3
input_measures = list()
for (i in 1:n_goods){
input_measures[[i]] = matrix(rnorm(n_pts*2), ncol=2)
}
for (i in (n_goods+1):(n_goods+n_bad)){
translated = matrix(rnorm(n_pts*2), ncol=2)
translated[,1] = translated[,1] + 20
input_measures[[i]] = translated
}
run_bary = rbaryGD(input_measures, num_support = n_pts)
run_median = rmedIRLS(input_measures, num_support = n_pts)
base1 = matrix(rnorm(100*2), ncol=2)
base2 = matrix(rnorm(20*2), ncol=2); base2[,1] = base2[,1]+20
base_mat = rbind(base1, base2)
plot(base_mat, col="grey80")
plot(base_mat, col="grey80", pch=19)
base1 = matrix(rnorm(200*2), ncol=2)
base2 = matrix(rnorm(50*2), ncol=2); base2[,1] = base2[,1]+20
base_mat = rbind(base1, base2)
plot(base_mat, col="grey80", pch=19)
abline(h=0); abline(v=0)
points(run_bary$support, col="blue")
points(run_bary$support, col="blue", pch=19)
points(run_median$support, col="red", pch=19)
n_pts = 30
n_goods = 12
n_bad = 8
input_measures = list()
for (i in 1:n_goods){
input_measures[[i]] = matrix(rnorm(n_pts*2), ncol=2)
}
for (i in (n_goods+1):(n_goods+n_bad)){
translated = matrix(rnorm(n_pts*2), ncol=2)
translated[,1] = translated[,1] + 20
input_measures[[i]] = translated
}
run_bary = rbaryGD(input_measures, num_support = n_pts)
run_median = rmedIRLS(input_measures, num_support = n_pts)
graphics.off()
run_bary = rbaryGD(input_measures, num_support = n_pts)
run_median = rmedIRLS(input_measures, num_support = n_pts)
base1 = matrix(rnorm(200*2), ncol=2)
base2 = matrix(rnorm(50*2), ncol=2); base2[,1] = base2[,1]+20
base_mat = rbind(base1, base2)
plot(base_mat, col="grey80", pch=19)
abline(h=0); abline(v=0)
points(run_bary$support, col="blue", pch=19)
points(run_median$support, col="red", pch=19)
run_median$history
## GENERATE DATA
#  8 empirical measures from class 1
input_measures = vector("list", length=10L)
for (i in 1:8){
input_measures[[i]] = matrix(rnorm(50*2), ncol=2)
}
for (j in 9:10){
base_draw = matrix(rnorm(50*2), ncol=2)
base_draw[,1] = base_draw[,1] + 20
input_measures[[j]] = base_draw
}
## COMPUTE
#  compute the Wasserstein median
run_median = rmedIRLS(input_measures, num_support = 50)
#  compute the Wasserstein barycenter
run_bary   = rbaryGD(input_measures, num_support = 50)
#  draw the base points of two classes
base_1 = matrix(rnorm(80*2), ncol=2)
base_2 = matrix(rnorm(20*2), ncol=2)
base_2[,1] = base_2[,1] + 20
base_mat = rbind(base_1, base_2)
plot(base_mat, col="gray80", pch=19)
title(main = expression("Estimated " *
phantom("barycenter") * phantom(" and ") * phantom("median")))
title(main = expression("Estimated " *
phantom("barycenter") * phantom(" and ") * phantom("median")))
title(main = expression("Estimated " *
textstyle(bold(phantom("barycenter")))), col.main="red", line=1.5)
title(main = expression(phantom("Estimated barycenter and ") *
textstyle(bold("median"))), col.main="blue", line=1.5)
title("estimated barycenter and median")
graphics.off()
base_1 = matrix(rnorm(80*2), ncol=2)
base_2 = matrix(rnorm(20*2), ncol=2)
base_2[,1] = base_2[,1] + 20
base_mat = rbind(base_1, base_2)
plot(base_mat, col="gray80", pch=19)
title("estimated barycenter and median")
#  draw the barycenter and the median
points(run_bary$support, col="red", pch=19)
points(run_median$support, col="blue", pch=19)
abline(v=0); abline(h=0)
graphics.off()
unlink(list.dirs("vignettes", recursive = FALSE, full.names = TRUE),
recursive = TRUE, force = TRUE)
unlink(Sys.glob("vignettes/**/*.{html,pdf,RData,rdb,rdx}"), force = TRUE)
list.files("vignettes", recursive = TRUE)
devtools::build_vignettes()
devtools::build_vignettes()
pkgdown::build_site()
pkgdown::clean_site()
pkgdown::build_site()
devtools::build_vignettes()
pkgdown::build_site()
help(rmedIRLS)
help(rbaryGD)
pkgdown::build_site()
n_pts = 10
n_goods = 7
n_bad = 3
input_measures = list()
for (i in 1:n_goods){
input_measures[[i]] = matrix(rnorm(n_pts*2), ncol=2)
}
for (i in (n_goods+1):(n_goods+n_bad)){
translated = matrix(rnorm(n_pts*2), ncol=2)
translated[,1] = translated[,1] + 20
input_measures[[i]] = translated
}
run_bary = rbaryGD(input_measures, num_support = n_pts)
run_medIRLS = rmedIRLS(input_measures, num_support = n_pts)
run_medPF = rmedPF(input_measures, num_support = n_pts)
# plot
base1 = matrix(rnorm(200*2), ncol=2)
base2 = matrix(rnorm(50*2), ncol=2); base2[,1] = base2[,1]+20
base_mat = rbind(base1, base2)
plot(base_mat, col="grey80", pch=19)
abline(h=0); abline(v=0)
points(run_bary$support, col="blue", pch=19)
points(run_medIRLS$support, col="red", pch=19)
points(run_medPF$support, col="green", pch=19)
rm(list=ls())
n_pts = 100
n_goods = 20
n_bad = 10
input_measures = list()
for (i in 1:n_goods){
input_measures[[i]] = matrix(rnorm(n_pts*2), ncol=2)
}
for (i in (n_goods+1):(n_goods+n_bad)){
translated = matrix(rnorm(n_pts*2), ncol=2)
translated[,1] = translated[,1] + 20
input_measures[[i]] = translated
}
microbenchmark::microbenchmark(
run_bary = rbaryGD(input_measures, num_support = n_pts),
run_medIRLS = rmedIRLS(input_measures, num_support = n_pts),
run_medPF = rmedPF(input_measures, num_support = n_pts),
times=3
)
rm(list=ls())
# runtime comparison
# personal example
# generate "n_good" measures from N(0, I)
#           "n_bad" measures from N(20, I)
n_pts = 50
n_goods = 15
n_bad = 5
input_measures = list()
for (i in 1:n_goods){
input_measures[[i]] = matrix(rnorm(n_pts*2), ncol=2)
}
for (i in (n_goods+1):(n_goods+n_bad)){
translated = matrix(rnorm(n_pts*2), ncol=2)
translated[,1] = translated[,1] + 20
input_measures[[i]] = translated
}
microbenchmark::microbenchmark(
run_bary = rbaryGD(input_measures, num_support = n_pts),
run_medIRLS = rmedIRLS(input_measures, num_support = n_pts),
run_medPF = rmedPF(input_measures, num_support = n_pts),
times=3
)
run_medIRLS = rmedIRLS(input_measures, num_support = n_pts),
run_bary = rbaryGD(input_measures, num_support = n_pts)
run_medIRLS = rmedIRLS(input_measures, num_support = n_pts)
run_medPF = rmedPF(input_measures, num_support = n_pts)
# plot
base1 = matrix(rnorm(200*2), ncol=2)
base2 = matrix(rnorm(50*2), ncol=2); base2[,1] = base2[,1]+20
base_mat = rbind(base1, base2)
plot(base_mat, col="grey80", pch=19)
abline(h=0); abline(v=0)
points(run_bary$support, col="blue", pch=19)
points(run_medIRLS$support, col="red", pch=19)
points(run_medPF$support, col="green", pch=19)
rm(list=ls())
# * class 2 : samples from N((20,0), Id)
#
#  We draw 8 empirical measures of size 50 from class 1, and
#  2 from class 2. All measures have uniform weights.
#-------------------------------------------------------------------
## GENERATE DATA
#  8 empirical measures from class 1
input_measures = vector("list", length=10L)
for (i in 1:8){
input_measures[[i]] = matrix(rnorm(50*2), ncol=2)
}
for (j in 9:10){
base_draw = matrix(rnorm(50*2), ncol=2)
base_draw[,1] = base_draw[,1] + 20
input_measures[[j]] = base_draw
}
## COMPUTE
#  compute the Wasserstein median
run_median = rmedPF(input_measures, num_support = 50)
#  compute the Wasserstein barycenter
run_bary   = rbaryGD(input_measures, num_support = 50)
## VISUALIZE
opar <- par(no.readonly=TRUE)
#  draw the base points of two classes
base_1 = matrix(rnorm(80*2), ncol=2)
base_2 = matrix(rnorm(20*2), ncol=2)
base_2[,1] = base_2[,1] + 20
base_mat = rbind(base_1, base_2)
plot(base_mat, col="gray80", pch=19)
#  auxiliary information
title("estimated barycenter and median")
abline(v=0); abline(h=0)
#  draw the barycenter and the median
points(run_bary$support, col="red", pch=19)
points(run_median$support, col="blue", pch=19)
par(opar)
